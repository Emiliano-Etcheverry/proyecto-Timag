{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A65tTkMoA-T"
      },
      "source": [
        "# Instalaci贸n de librer铆as necesar铆as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mpUIoXQm0s2"
      },
      "outputs": [],
      "source": [
        "!pip install comet-ml keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK8zuMQboH1w"
      },
      "source": [
        "# Importaci贸n de librer铆as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YioNHD3-zr9F",
        "outputId": "34076e79-cad9-4e9a-fdd3-1b3febad9c90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import comet_ml\n",
        "\n",
        "from comet_ml import Experiment\n",
        "\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import librosa # Comentarios\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "# Configurmos para usar GPU\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deL9BfvGrrHv"
      },
      "source": [
        "# Funciones auxiliares (m茅tricas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_Y4b3AJIla7"
      },
      "outputs": [],
      "source": [
        "class F1Macro(tf.keras.metrics.Metric):\n",
        "    def __init__(self, num_labels=80, threshold=0.5, name=\"f1_macro\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.th = threshold\n",
        "        self.tp = self.add_weight(name=\"tp\", shape=(num_labels,), initializer=\"zeros\")\n",
        "        self.fp = self.add_weight(name=\"fp\", shape=(num_labels,), initializer=\"zeros\")\n",
        "        self.fn = self.add_weight(name=\"fn\", shape=(num_labels,), initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # 1) Alinea tipos\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "        # 2) Binariza s贸lo la predicci贸n\n",
        "        y_pred = tf.cast(y_pred > self.th, tf.float32)\n",
        "\n",
        "        # Si tus y_true ya son 0/1, no hace falta umbralizarlas\n",
        "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred, axis=0))\n",
        "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred, axis=0))\n",
        "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred), axis=0))\n",
        "\n",
        "    def result(self):\n",
        "        precision = tf.math.divide_no_nan(self.tp, self.tp + self.fp)\n",
        "        recall    = tf.math.divide_no_nan(self.tp, self.tp + self.fn)\n",
        "        f1        = tf.math.divide_no_nan(2 * precision * recall, precision + recall)\n",
        "        return tf.reduce_mean(f1)\n",
        "\n",
        "    def reset_state(self):\n",
        "        for v in (self.tp, self.fp, self.fn):\n",
        "            v.assign(tf.zeros_like(v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxYMW_8I6Z1n"
      },
      "outputs": [],
      "source": [
        "# Core calculation of label precisions for one test sample.\n",
        "\n",
        "def _one_sample_positive_class_precisions(scores, truth):\n",
        "  \"\"\"Calculate precisions for each true class for a single sample.\n",
        "\n",
        "  Args:\n",
        "    scores: np.array of (num_classes,) giving the individual classifier scores.\n",
        "    truth: np.array of (num_classes,) bools indicating which classes are true.\n",
        "\n",
        "  Returns:\n",
        "    pos_class_indices: np.array of indices of the true classes for this sample.\n",
        "    pos_class_precisions: np.array of precisions corresponding to each of those\n",
        "      classes.\n",
        "  \"\"\"\n",
        "  num_classes = scores.shape[0]\n",
        "  pos_class_indices = np.flatnonzero(truth > 0)\n",
        "  # Only calculate precisions if there are some true classes.\n",
        "  if not len(pos_class_indices):\n",
        "    return pos_class_indices, np.zeros(0)\n",
        "  # Retrieval list of classes for this sample.\n",
        "  retrieved_classes = np.argsort(scores)[::-1]\n",
        "  # class_rankings[top_scoring_class_index] == 0 etc.\n",
        "  class_rankings = np.zeros(num_classes, dtype=np.int32)\n",
        "  class_rankings[retrieved_classes] = range(num_classes)\n",
        "  # Which of these is a true label?\n",
        "  retrieved_class_true = np.zeros(num_classes, dtype=np.bool_)\n",
        "  retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
        "  # Num hits for every truncated retrieval list.\n",
        "  retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
        "  # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
        "  precision_at_hits = (\n",
        "      retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
        "      (1 + class_rankings[pos_class_indices].astype(float)))\n",
        "  return pos_class_indices, precision_at_hits\n",
        "\n",
        "# All-in-one calculation of per-class lwlrap.\n",
        "\n",
        "def calculate_per_class_lwlrap(truth, scores):\n",
        "  \"\"\"Calculate label-weighted label-ranking average precision.\n",
        "\n",
        "  Arguments:\n",
        "    truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
        "      of presence of that class in that sample.\n",
        "    scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
        "      test's real-valued score for each class for each sample.\n",
        "\n",
        "  Returns:\n",
        "    per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
        "      class.\n",
        "    weight_per_class: np.array of (num_classes,) giving the prior of each\n",
        "      class within the truth labels.  Then the overall unbalanced lwlrap is\n",
        "      simply np.sum(per_class_lwlrap * weight_per_class)\n",
        "  \"\"\"\n",
        "  assert truth.shape == scores.shape\n",
        "  num_samples, num_classes = scores.shape\n",
        "  # Space to store a distinct precision value for each class on each sample.\n",
        "  # Only the classes that are true for each sample will be filled in.\n",
        "  precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
        "  for sample_num in range(num_samples):\n",
        "    pos_class_indices, precision_at_hits = (\n",
        "      _one_sample_positive_class_precisions(scores[sample_num, :],\n",
        "                                            truth[sample_num, :]))\n",
        "    precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
        "        precision_at_hits)\n",
        "  labels_per_class = np.sum(truth > 0, axis=0)\n",
        "  weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
        "  # Form average of each column, i.e. all the precisions assigned to labels in\n",
        "  # a particular class.\n",
        "  per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
        "                      np.maximum(1, labels_per_class))\n",
        "  # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
        "  #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
        "  #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
        "  #                = np.sum(per_class_lwlrap * weight_per_class)\n",
        "  return per_class_lwlrap, weight_per_class\n",
        "\n",
        "\n",
        "# Calculate the overall lwlrap using sklearn.metrics function.\n",
        "\n",
        "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
        "  \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
        "  # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
        "  sample_weight = np.sum(truth > 0, axis=1)\n",
        "  nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
        "  overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
        "      truth[nonzero_weight_sample_indices, :] > 0,\n",
        "      scores[nonzero_weight_sample_indices, :],\n",
        "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
        "  return overall_lwlrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Coy_0iRsVBRa"
      },
      "outputs": [],
      "source": [
        "# Accumulator object version.\n",
        "\n",
        "class lwlrap_accumulator(object):\n",
        "  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.num_classes = 0\n",
        "    self.total_num_samples = 0\n",
        "\n",
        "  def accumulate_samples(self, batch_truth, batch_scores):\n",
        "    \"\"\"Cumulate a new batch of samples into the metric.\n",
        "\n",
        "    Args:\n",
        "      truth: np.array of (num_samples, num_classes) giving boolean\n",
        "        ground-truth of presence of that class in that sample for this batch.\n",
        "      scores: np.array of (num_samples, num_classes) giving the\n",
        "        classifier-under-test's real-valued score for each class for each\n",
        "        sample.\n",
        "    \"\"\"\n",
        "    assert batch_scores.shape == batch_truth.shape\n",
        "    num_samples, num_classes = batch_truth.shape\n",
        "    if not self.num_classes:\n",
        "      self.num_classes = num_classes\n",
        "      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n",
        "      self._per_class_cumulative_count = np.zeros(self.num_classes,\n",
        "                                                  dtype=np.int32)\n",
        "    assert num_classes == self.num_classes\n",
        "    for truth, scores in zip(batch_truth, batch_scores):\n",
        "      pos_class_indices, precision_at_hits = (\n",
        "        _one_sample_positive_class_precisions(scores, truth))\n",
        "      self._per_class_cumulative_precision[pos_class_indices] += (\n",
        "        precision_at_hits)\n",
        "      self._per_class_cumulative_count[pos_class_indices] += 1\n",
        "    self.total_num_samples += num_samples\n",
        "\n",
        "  def per_class_lwlrap(self):\n",
        "    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n",
        "    return (self._per_class_cumulative_precision /\n",
        "            np.maximum(1, self._per_class_cumulative_count))\n",
        "\n",
        "  def per_class_weight(self):\n",
        "    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n",
        "    return (self._per_class_cumulative_count /\n",
        "            float(np.sum(self._per_class_cumulative_count)))\n",
        "\n",
        "  def overall_lwlrap(self):\n",
        "    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n",
        "    return np.sum(self.per_class_lwlrap() * self.per_class_weight())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpmvX-DZ-1Ln"
      },
      "outputs": [],
      "source": [
        "# Funci贸n para extraer labels de datasets batcheados\n",
        "def extract_labels_from_dataset(dataset):\n",
        "    \"\"\"Extrae todas las labels de un dataset batcheado\"\"\"\n",
        "    all_labels = []\n",
        "    for batch_data, batch_labels in dataset:\n",
        "        all_labels.append(batch_labels.numpy())\n",
        "    return np.concatenate(all_labels, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u09SBdmW_NqE",
        "outputId": "c6adea44-0bc0-403d-96ff-68779c98d7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== LWLRAP CON ACCUMULATOR ===\n",
            "Train LWLRAP (accumulator): 0.0631\n",
            "Validation LWLRAP (accumulator): 0.0963\n",
            "=== EVALUANDO MOBILENET-CURATED ===\n",
            "Realizando predicciones...\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 177ms/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 211ms/step\n",
            "Extrayendo labels...\n",
            "Train: (3479, 80) labels, (3479, 80) predictions\n",
            "Val: (745, 80) labels, (745, 80) predictions\n",
            "\n",
            "--- ENTRENAMIENTO ---\n",
            "LWLRAP Train: 0.0653\n",
            "\n",
            "--- VALIDACIN ---\n",
            "LWLRAP Validation: 0.0963\n",
            "\n",
            "--- ANLISIS POR CLASE ---\n",
            "Top 5 clases (mejor LWLRAP):\n",
            "  1. Writing: 0.7381 (peso: 0.0105)\n",
            "  2. Church_bell: 0.6339 (peso: 0.0210)\n",
            "  3. Sink_(filling_or_washing): 0.5312 (peso: 0.0093)\n",
            "  4. Water_tap_and_faucet: 0.4444 (peso: 0.0105)\n",
            "  5. Computer_keyboard: 0.4444 (peso: 0.0187)\n",
            "\n",
            "Bottom 5 clases (peor LWLRAP):\n",
            "  1. Hi-hat: 0.0162 (peso: 0.0105)\n",
            "  2. Accordion: 0.0159 (peso: 0.0082)\n",
            "  3. Fart: 0.0156 (peso: 0.0082)\n",
            "  4. Finger_snapping: 0.0152 (peso: 0.0117)\n",
            "  5. Bus: 0.0145 (peso: 0.0129)\n"
          ]
        }
      ],
      "source": [
        "# Calcular LWLRAP usando accumulator (m谩s eficiente)\n",
        "def calculate_lwlrap_accumulator(labels, predictions, batch_size=32):\n",
        "    \"\"\"Calcula LWLRAP usando accumulator\"\"\"\n",
        "    accumulator = lwlrap_accumulator()\n",
        "\n",
        "    num_samples = labels.shape[0]\n",
        "    for start_idx in range(0, num_samples, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, num_samples)\n",
        "        batch_labels = labels[start_idx:end_idx]\n",
        "        batch_preds = predictions[start_idx:end_idx]\n",
        "        accumulator.accumulate_samples(batch_labels, batch_preds)\n",
        "\n",
        "    return accumulator.overall_lwlrap()\n",
        "\n",
        "def evaluate_model_lwlrap(model, train_dataset, val_dataset, model_name=\"modelo\"):\n",
        "    \"\"\"\n",
        "    Evaluaci贸n completa del modelo con LWLRAP\n",
        "    \"\"\"\n",
        "    print(f\"=== EVALUANDO {model_name.upper()} ===\")\n",
        "\n",
        "    # Hacer predicciones\n",
        "    print(\"Realizando predicciones...\")\n",
        "    pred_train = model.predict(train_dataset, verbose=1)\n",
        "    pred_val = model.predict(val_dataset, verbose=1)\n",
        "\n",
        "    # Extraer labels\n",
        "    print(\"Extrayendo labels...\")\n",
        "    labels_train = extract_labels_from_dataset(train_dataset)\n",
        "    labels_val = extract_labels_from_dataset(val_dataset)\n",
        "\n",
        "    # Verificar dimensiones\n",
        "    print(f\"Train: {labels_train.shape} labels, {pred_train.shape} predictions\")\n",
        "    print(f\"Val: {labels_val.shape} labels, {pred_val.shape} predictions\")\n",
        "\n",
        "    # Calcular LWLRAP\n",
        "    print(\"\\n--- ENTRENAMIENTO ---\")\n",
        "    train_lwlrap = calculate_lwlrap_accumulator(labels_train, pred_train)\n",
        "    print(f\"LWLRAP Train: {train_lwlrap:.4f}\")\n",
        "\n",
        "    print(\"\\n--- VALIDACIN ---\")\n",
        "    val_lwlrap = calculate_lwlrap_accumulator(labels_val, pred_val)\n",
        "    print(f\"LWLRAP Validation: {val_lwlrap:.4f}\")\n",
        "\n",
        "    # An谩lisis por clase (opcional)\n",
        "    print(\"\\n--- ANLISIS POR CLASE ---\")\n",
        "    per_class_lwlrap, weight_per_class = calculate_per_class_lwlrap(labels_val, pred_val)\n",
        "\n",
        "    # Mostrar las mejores y peores clases\n",
        "    class_performance = list(zip(all_labels, per_class_lwlrap, weight_per_class))\n",
        "    class_performance.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(\"Top 5 clases (mejor LWLRAP):\")\n",
        "    for i, (label, lwlrap, weight) in enumerate(class_performance[:5]):\n",
        "        print(f\"  {i+1}. {label}: {lwlrap:.4f} (peso: {weight:.4f})\")\n",
        "\n",
        "    print(\"\\nBottom 5 clases (peor LWLRAP):\")\n",
        "    for i, (label, lwlrap, weight) in enumerate(class_performance[-5:]):\n",
        "        print(f\"  {i+1}. {label}: {lwlrap:.4f} (peso: {weight:.4f})\")\n",
        "\n",
        "    return {\n",
        "        'train_lwlrap': train_lwlrap,\n",
        "        'val_lwlrap': val_lwlrap,\n",
        "        'per_class_lwlrap': per_class_lwlrap,\n",
        "        'weight_per_class': weight_per_class,\n",
        "        'train_predictions': pred_train,\n",
        "        'val_predictions': pred_val,\n",
        "        'train_labels': labels_train,\n",
        "        'val_labels': labels_val\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRU500idnegw"
      },
      "source": [
        "# Link a tfrecords:\n",
        "https://drive.google.com/drive/folders/1WAlJPGbOhqPaX79pPYzeOekEzAilskGO?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA-cUcteEo5l",
        "outputId": "e7acbf24-0ace-4f96-f1df-35725020e069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROH8LYtEoN43"
      },
      "source": [
        "# Lectura de datos\n",
        "(CSV y tfrecords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGjIwUQpNTb0"
      },
      "outputs": [],
      "source": [
        "# Ruta en Drive (ya montado)\n",
        "#base_dir = Path('/content/drive/MyDrive/taa-2025-freesound-audio-tagging')\n",
        "base_dir = Path('/content/drive/MyDrive/Facultad/TAA/Proyecto2/taa-2025-freesound-audio-tagging') #Facundo\n",
        "\n",
        "# Cargar CSVs\n",
        "train_curated_df = pd.read_csv(base_dir / 'train_curated.csv')\n",
        "train_curated_df = train_curated_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_noisy_df   = pd.read_csv(base_dir / 'train_noisy.csv')\n",
        "train_noisy_df   = train_noisy_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "test_df          = pd.read_csv(base_dir / 'sample_submission_v24.csv')\n",
        "vocab_df         = pd.read_csv(base_dir / 'vocabulary.csv', header=None)\n",
        "\n",
        "# Extraer etiquetas\n",
        "all_labels = vocab_df[1].tolist()\n",
        "label_to_index = {label: i for i, label in enumerate(all_labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaC0Xr8VTrbF"
      },
      "outputs": [],
      "source": [
        "size_train_curated = len(train_curated_df)\n",
        "size_train_noisy = len(train_noisy_df)\n",
        "size_test = len(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOJN0wqTBaNF"
      },
      "source": [
        "# Funciones para lectura de tfrecords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcW8HV67bE-P"
      },
      "outputs": [],
      "source": [
        "def parse_tfrecord_fn(example, num_classes):\n",
        "  feature_description = {\n",
        "      'audio': tf.io.FixedLenFeature([], tf.string, default_value=''), # Changed from VarLenFeature to FixedLenFeature\n",
        "      'label': tf.io.FixedLenFeature([num_classes],tf.int64)\n",
        "  }\n",
        "  parsed = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "  # Decodificar audio WAV\n",
        "  audio, _ = tf.audio.decode_wav(parsed['audio'])\n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "  label = parsed['label']\n",
        "  return audio, label\n",
        "\n",
        "def get_tfrecord_dataset(tfrecord_path, num_classes):\n",
        "  dataset = tf.data.TFRecordDataset(str(tfrecord_path))\n",
        "  dataset = dataset.map(lambda x: parse_tfrecord_fn(x, num_classes),)\n",
        "  return dataset\n",
        "\n",
        "def parse_tfrecord_test_fn(example):\n",
        "  feature_description = {\n",
        "      'audio': tf.io.FixedLenFeature([], tf.string, default_value=''), # Changed from VarLenFeature to FixedLenFeature\n",
        "  }\n",
        "  parsed = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "  # Decodificar audio WAV\n",
        "  audio, _ = tf.audio.decode_wav(parsed['audio'])\n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "\n",
        "  return audio\n",
        "\n",
        "def get_tfrecord_test_dataset(tfrecord_path):\n",
        "  dataset = tf.data.TFRecordDataset(str(tfrecord_path))\n",
        "  dataset = dataset.map(lambda x: parse_tfrecord_test_fn(x),)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgyD4lncpKW8"
      },
      "source": [
        "# Creaci贸n de datasets de audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXGjRhg_BoUK"
      },
      "outputs": [],
      "source": [
        "curated_train_resampled_ds = get_tfrecord_dataset(base_dir / 'train_curated_resampled.tfrecord', len(all_labels))\n",
        "curated_train_ds = get_tfrecord_dataset(base_dir / 'train_curated.tfrecord', len(all_labels))\n",
        "noisy_train_resampled_ds = get_tfrecord_dataset(base_dir / 'train_noisy_resampled.tfrecord', len(all_labels))\n",
        "noisy_train_ds = get_tfrecord_dataset(base_dir / 'train_noisy.tfrecord', len(all_labels))\n",
        "test_resampled_ds = get_tfrecord_test_dataset(base_dir / 'test_resampled.tfrecord')\n",
        "test_ds = get_tfrecord_test_dataset(base_dir / 'test.tfrecord')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "katZ4T6-o7an"
      },
      "source": [
        "# Funciones de preprocesado de datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSEm_dqKeoDJ"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram_mfccs(waveform, sample_rate):\n",
        "        # Padding/truncado a 25 segundos con esto aseguro el percentil 95 en noisy\n",
        "        desired_samples = sample_rate * 25\n",
        "        audio_len = tf.shape(waveform)[0]\n",
        "        waveform = tf.cond(audio_len < desired_samples,\n",
        "                            lambda: tf.pad(waveform, [[0, desired_samples - audio_len]]),\n",
        "                            lambda: waveform[:desired_samples])\n",
        "        # Calculo de STFT\n",
        "        stft = tf.signal.stft(waveform, frame_length=1024, frame_step=512, fft_length=1024, window_fn=tf.signal.hann_window)\n",
        "        spectrogram = tf.abs(stft)\n",
        "\n",
        "        # Se define el banco de filtros a utilizar\n",
        "        num_spectrogram_bins = stft.shape[-1]\n",
        "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0, 4000, 80\n",
        "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "                                                                            num_mel_bins,\n",
        "                                                                            num_spectrogram_bins,\n",
        "                                                                            sample_rate,\n",
        "                                                                            lower_edge_hertz,\n",
        "                                                                            upper_edge_hertz\n",
        "                                                                        )\n",
        "\n",
        "        # Se aplica el banco de filtros sobre el espctrograma\n",
        "        mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
        "        mel_spectrogram.set_shape(spectrogram.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "        # Calculo el Espectrograma en magnitud logar铆tmica y escala mel\n",
        "        log_mel = tf.math.log(mel_spectrogram + 1e-6)\n",
        "\n",
        "        # Calculo los MFCCs a partir del log_mel y tomo los 13 primeros\n",
        "        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel)[..., :13]\n",
        "        return tf.expand_dims(mfccs, axis=-1)\n",
        "\n",
        "def preprocess_audio(audio, label, sample_rate=16000):\n",
        "    # Aplicar espectrograma\n",
        "    spectrogram = get_spectrogram_mfccs(audio, sample_rate)\n",
        "    return spectrogram, label\n",
        "\n",
        "def preprocess_audio_test(audio, sample_rate=16000):\n",
        "    # Aplicar espectrograma\n",
        "    spectrogram = get_spectrogram_mfccs(audio, sample_rate)\n",
        "    return spectrogram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeJaGR98pWJH"
      },
      "source": [
        "# Preprocesado / Obtenci贸n de Espectrogramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLMDdA6hfFLU"
      },
      "outputs": [],
      "source": [
        "spect_curated_train_resampled_ds = curated_train_resampled_ds.map(lambda audio, label: preprocess_audio(audio, label, sample_rate=16000), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "spect_curated_train_ds = curated_train_ds.map(lambda audio, label: preprocess_audio(audio, label, sample_rate=44100), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "spect_noisy_train_resampled_ds = noisy_train_resampled_ds.map(lambda audio, label: preprocess_audio(audio, label, sample_rate=16000), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "spect_noisy_train_ds = noisy_train_ds.map(lambda audio, label: preprocess_audio(audio, label, sample_rate=44100), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "spect_test_resampled_ds = test_resampled_ds.map(lambda audio: preprocess_audio_test(audio, sample_rate=16000), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "spect_test_ds = test_ds.map(lambda audio: preprocess_audio_test(audio, sample_rate=44100), num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aZ8Dj6IqPmI"
      },
      "source": [
        "# Funciones auxiliares para Split y Mix de datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8HxcmZQqZlU"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, size,train_frac=0.8):\n",
        "    train_size = int(size * train_frac)\n",
        "    train_ds = dataset.take(train_size)\n",
        "    val_ds = dataset.skip(train_size)\n",
        "    return train_ds, val_ds\n",
        "\n",
        "def split_dataset_3way(dataset, size, train_frac=0.7, val_frac=0.15):\n",
        "    train_size = int(size * train_frac)\n",
        "    val_size = int(size * val_frac)\n",
        "\n",
        "    train_ds = dataset.take(train_size)\n",
        "    val_ds = dataset.skip(train_size).take(val_size)\n",
        "    dev_ds = dataset.skip(train_size + val_size)\n",
        "\n",
        "    return train_ds, val_ds, dev_ds\n",
        "\n",
        "def mix_datasets(ds_curated, ds_noisy):\n",
        "  # Porcentajes relativos\n",
        "  proportion_curated = 0.7\n",
        "  proportion_noisy = 0.3\n",
        "\n",
        "  # Mezcla proporcional\n",
        "  mixed_dataset = tf.data.Dataset.sample_from_datasets(\n",
        "      [ds_curated, ds_noisy],\n",
        "      weights=[proportion_curated, proportion_noisy],\n",
        "      seed=42\n",
        "  )\n",
        "\n",
        "  # Shuffle, batching y prefetch despu茅s\n",
        "  batch_ds = mixed_dataset.shuffle(1000).batch(32).cache().prefetch(tf.data.AUTOTUNE)\n",
        "  return batch_ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NynLKOUWpxai"
      },
      "source": [
        "# Split de entrenamiento y validaci贸n. Batcheado y mezcla de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvmGkWMCPwjJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# Separaci贸n en entrenamiento y validaci贸n\n",
        "batch_noisy_train_ds, batch_noisy_val_ds = split_dataset(spect_noisy_train_ds, size=size_train_noisy, train_frac=0.8)\n",
        "batch_noisy_resampled_train_ds, batch_noisy_resampled_val_ds = split_dataset(spect_noisy_train_resampled_ds, size=size_train_noisy, train_frac=0.8)\n",
        "batch_curated_train_ds, batch_curated_val_ds = split_dataset(spect_curated_train_ds, size=size_train_curated, train_frac=0.8)\n",
        "batch_curated_resampled_train_ds, batch_curated_resampled_val_ds = split_dataset(spect_curated_train_resampled_ds, size=size_train_curated, train_frac=0.8)\n",
        "\n",
        "# Creo datasets mezclados\n",
        "mixed_train_ds = mix_datasets(batch_noisy_train_ds, batch_curated_train_ds)\n",
        "mixed_val_ds = mix_datasets(batch_noisy_val_ds, batch_curated_val_ds)\n",
        "\n",
        "mixed_train_resampled_ds = mix_datasets(batch_noisy_resampled_train_ds, batch_curated_resampled_train_ds)\n",
        "mixed_val_resampled_ds = mix_datasets(batch_noisy_resampled_val_ds, batch_curated_resampled_val_ds)\n",
        "\n",
        "# Batcheado\n",
        "# Agrego las operaciones Dataset.cache y Dataset.prefetch para reducir la latencia de lectura mientras entrena el modelo\n",
        "batch_noisy_train_ds = batch_noisy_train_ds.shuffle(1000).batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "batch_noisy_val_ds = batch_noisy_val_ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "batch_noisy_resampled_train_ds = batch_noisy_resampled_train_ds.shuffle(1000).batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "batch_noisy_resampled_val_ds = batch_noisy_resampled_val_ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "batch_curated_train_ds = batch_curated_train_ds.shuffle(1000).batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "batch_curated_val_ds = batch_curated_val_ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "batch_curated_resampled_train_ds = batch_curated_resampled_train_ds.shuffle(1000).cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "batch_curated_resampled_val_ds = batch_curated_resampled_val_ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flCh0iZxtDK2"
      },
      "source": [
        "# Funciones de aumentado de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcvT24o99WW7"
      },
      "outputs": [],
      "source": [
        "def mixup_individual(spectrogram, label, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Aplica Mixup entre un ejemplo individual y otro aleatorio del dataset.\n",
        "    \"\"\"\n",
        "    dataset_global = mixup_individual.dataset\n",
        "\n",
        "    # Obtener otro ejemplo aleatorio\n",
        "    other_spectrogram, other_label = next(iter(dataset_global.shuffle(1000).take(1)))\n",
        "\n",
        "    # Asegurar que todo sea float32 para operar\n",
        "    spectrogram = tf.cast(spectrogram, tf.float32)\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    other_spectrogram = tf.cast(other_spectrogram, tf.float32)\n",
        "    other_label = tf.cast(other_label, tf.float32)\n",
        "\n",
        "    # Generar lambda\n",
        "    lam = tf.random.gamma(shape=[], alpha=alpha, beta=alpha + 1)\n",
        "    lam = tf.clip_by_value(lam, 0.0, 1.0)\n",
        "\n",
        "    # Mezclar\n",
        "    mixed_spectrogram = lam * spectrogram + (1.0 - lam) * other_spectrogram\n",
        "    mixed_label = lam * label + (1.0 - lam) * other_label\n",
        "\n",
        "    return mixed_spectrogram, mixed_label\n",
        "\n",
        "def spec_augment(spectrogram, input_shape, freq_mask_param=15, time_mask_param=35, num_masks=2):\n",
        "    \"\"\"\n",
        "    Aplica SpecAugment: frequency masking y time masking.\n",
        "    VERSIN CORREGIDA con validaci贸n de l铆mites.\n",
        "    \"\"\"\n",
        "    # Ensure spectrogram has at least 3 dimensions (height, width, channels)\n",
        "    spectrogram = tf.ensure_shape(spectrogram, [input_shape, 13, 1])\n",
        "\n",
        "    # Obtener dimensiones\n",
        "    freq_max, time_max = tf.shape(spectrogram)[0], tf.shape(spectrogram)[1]\n",
        "\n",
        "    # Convertir a int32 para evitar problemas de tipos\n",
        "    freq_max = tf.cast(freq_max, tf.int32)\n",
        "    time_max = tf.cast(time_max, tf.int32)\n",
        "\n",
        "    # Frequency masking\n",
        "    for _ in range(num_masks):\n",
        "        # Ensure freq_max is at least 1 before masking\n",
        "        if tf.greater(freq_max, 1):\n",
        "            # Asegurar que freq_mask_param no sea mayor que freq_max\n",
        "            f_param = tf.minimum(freq_mask_param, freq_max - 1)\n",
        "            f_param = tf.maximum(f_param, 1)  # Asegurar que sea al menos 1\n",
        "\n",
        "            f = tf.random.uniform([], 0, f_param, dtype=tf.int32)\n",
        "            f = tf.minimum(f, freq_max - 1)  # Asegurar que f < freq_max\n",
        "\n",
        "            # Calcular f0 de manera segura\n",
        "            max_f0 = tf.maximum(freq_max - f, 1)\n",
        "            f0 = tf.random.uniform([], 0, max_f0, dtype=tf.int32)\n",
        "            f0 = tf.minimum(f0, freq_max - f)  # Asegurar que f0 + f <= freq_max\n",
        "\n",
        "            # Crear m谩scara vertical solo si tenemos dimensions v谩lidas\n",
        "            if tf.greater(f, 0) and tf.greater(f0, 0):\n",
        "                mask = tf.concat([\n",
        "                    tf.ones([f0, time_max, tf.shape(spectrogram)[2]], dtype=spectrogram.dtype),\n",
        "                    tf.zeros([f, time_max, tf.shape(spectrogram)[2]], dtype=spectrogram.dtype),\n",
        "                    tf.ones([freq_max - f0 - f, time_max, tf.shape(spectrogram)[2]], dtype=spectrogram.dtype)\n",
        "                ], axis=0)\n",
        "                spectrogram = spectrogram * mask\n",
        "\n",
        "    # Time masking\n",
        "    for _ in range(num_masks):\n",
        "        # Ensure time_max is at least 1 before masking\n",
        "        if tf.greater(time_max, 1):\n",
        "            # Asegurar que time_mask_param no sea mayor que time_max\n",
        "            t_param = tf.minimum(time_mask_param, time_max - 1)\n",
        "            t_param = tf.maximum(t_param, 1)  # Asegurar que sea al menos 1\n",
        "\n",
        "            t = tf.random.uniform([], 0, t_param, dtype=tf.int32)\n",
        "            t = tf.minimum(t, time_max - 1)  # Asegurar que t < time_max\n",
        "\n",
        "            # Calcular t0 de manera segura\n",
        "            max_t0 = tf.maximum(time_max - t, 1)\n",
        "            t0 = tf.random.uniform([], 0, max_t0, dtype=tf.int32)\n",
        "            t0 = tf.minimum(t0, time_max - t)  # Asegurar que t0 + t <= time_max\n",
        "\n",
        "            # Crear m谩scara horizontal solo si tenemos dimensiones v谩lidas\n",
        "            if tf.greater(t, 0) and tf.greater(t0, 0):\n",
        "                mask = tf.concat([\n",
        "                    tf.ones([freq_max, t0, tf.shape(spectrogram)[2]], dtype=spectrogram.dtype),\n",
        "                    tf.zeros([freq_max, t, tf.shape(spectrogram)[2]], dtype=spectrogram.dtype),\n",
        "                    tf.ones([freq_max, time_max - t0 - t, tf.shape(spectrogram)[2]], dtype=spectrogram.dtype)\n",
        "                ], axis=1)\n",
        "                spectrogram = spectrogram * mask\n",
        "\n",
        "    return spectrogram\n",
        "\n",
        "def brightness_contrast_augmentation(spectrogram, input_shape, brightness_range=0.1, contrast_range=0.1):\n",
        "    \"\"\"\n",
        "    Aplica ajustes de brillo y contraste al espectrograma.\n",
        "    VERSIN CORREGIDA con rangos m谩s conservadores.\n",
        "    \"\"\"\n",
        "    # Ensure spectrogram has at least 3 dimensions (height, width, channels)\n",
        "    spectrogram = tf.ensure_shape(spectrogram, [input_shape, 13, 1])\n",
        "\n",
        "    # Ajuste de brillo m谩s conservador\n",
        "    brightness_delta = tf.random.uniform([], -brightness_range, brightness_range)\n",
        "    spectrogram = spectrogram + brightness_delta\n",
        "\n",
        "    # Ajuste de contraste m谩s conservador\n",
        "    contrast_factor = tf.random.uniform([], 1 - contrast_range, 1 + contrast_range)\n",
        "    mean_val = tf.reduce_mean(spectrogram)\n",
        "    spectrogram = (spectrogram - mean_val) * contrast_factor + mean_val\n",
        "\n",
        "    # Clip a un rango m谩s amplio para evitar saturaci贸n\n",
        "    return tf.clip_by_value(spectrogram, -10.0, 10.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ7VovuRE9t5"
      },
      "outputs": [],
      "source": [
        "# Helper para asegurar dtype y shape\n",
        "def safe_spec_augment(x, y):\n",
        "    spec = spec_augment(x, input_shape=2152)\n",
        "    print(\"Before ensure_shape:\", x.shape)\n",
        "    print(\"After ensure_shape:\", spec.shape)\n",
        "    spec = tf.ensure_shape(spec, x.shape)\n",
        "    spec = tf.cast(spec, tf.float32)\n",
        "    return spec, y\n",
        "\n",
        "def safe_brightness_augment(x, y):\n",
        "    spec = brightness_contrast_augmentation(x, input_shape=2152)\n",
        "    print(\"Before ensure_shape:\", x.shape)\n",
        "    print(\"After ensure_shape:\", spec.shape)\n",
        "    spec = tf.ensure_shape(spec, x.shape)\n",
        "    spec = tf.cast(spec, tf.float32)\n",
        "    return spec, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brVBm0OKs94S"
      },
      "source": [
        "# Aumentado de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0F3QpMTFCGo",
        "outputId": "7f08fa98-a50b-45a6-9c13-334f011ff1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before ensure_shape: (None, 13, 1)\n",
            "After ensure_shape: (2152, 13, 1)\n",
            "Before ensure_shape: (None, 13, 1)\n",
            "After ensure_shape: (2152, 13, 1)\n"
          ]
        }
      ],
      "source": [
        "# Unbatch y aplicar augmentations seguras\n",
        "spec_augmented_ds = mixed_train_ds.unbatch().map(\n",
        "    safe_spec_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "bright_augmented_ds = mixed_train_ds.unbatch().map(\n",
        "    safe_brightness_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Concatenar augmentaciones\n",
        "augmented_ds = spec_augmented_ds.concatenate(bright_augmented_ds)\n",
        "\n",
        "# Agregar tambi茅n los datos originales\n",
        "original_ds = mixed_train_ds.unbatch().map(lambda x, y: (tf.ensure_shape(x, (2152, 13, 1)), y))\n",
        "\n",
        "augmented_ds = augmented_ds.concatenate(original_ds)\n",
        "\n",
        "# Shuffle, batch y cache\n",
        "augmented_ds = (augmented_ds\n",
        "                .shuffle(1000)\n",
        "                .batch(batch_size)\n",
        "                .cache()\n",
        "                .prefetch(tf.data.AUTOTUNE))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOHDYuggvIRm"
      },
      "source": [
        "Cuento pasos por epoca para el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZeQKa6TC0v-",
        "outputId": "c19d169e-5b25-457f-a2d6-6e901e1d93ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Element specification of augmented_ds:\n",
            "(TensorSpec(shape=(None, 2152, 13, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 80), dtype=tf.int64, name=None))\n",
            "Number of training samples (augmented): 59484\n"
          ]
        }
      ],
      "source": [
        "def count_samples_in_batched_dataset(dataset):\n",
        "    \"\"\"\n",
        "    Cuenta el n煤mero total de muestras en un dataset que puede estar batcheado o no.\n",
        "    \"\"\"\n",
        "    total_samples = 0\n",
        "    for batch in dataset:\n",
        "        if isinstance(batch, tuple):\n",
        "            batch_data = batch[0]\n",
        "        else:\n",
        "            batch_data = batch\n",
        "        batch_size = tf.shape(batch_data)[0]\n",
        "        total_samples += int(batch_size.numpy())\n",
        "    return total_samples\n",
        "\n",
        "# Revisi贸n de shape\n",
        "print(\"Especificaciones augmented_ds:\")\n",
        "print(augmented_ds.element_spec)\n",
        "\n",
        "\n",
        "# Contar muestras correctamente\n",
        "n_train = count_samples_in_batched_dataset(augmented_ds)\n",
        "print(f\"Steps per epoch (augmented): {n_train//32}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-ew8yZgtJaZ"
      },
      "source": [
        "# Definici贸n de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLFqoE9-n3gA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def build_efficientnetv2_b2_scratch(input_shape=(224, 224, 3), num_classes=80, dropout_rate=0.3, lr=1e-3):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Resizing(256, 256)(inputs)\n",
        "    x = tf.keras.layers.Concatenate(axis=-1)([x,x,x])\n",
        "\n",
        "    base_model = tf.keras.applications.EfficientNetV2B2(\n",
        "        include_top=False,\n",
        "        weights=None,  #  ENTRENADO DESDE CERO\n",
        "        input_shape=(256,256,3),\n",
        "    )\n",
        "\n",
        "    x = base_model(x, training=True)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[tf.keras.metrics.AUC(name='auc', multi_label=True),\n",
        "                 F1Macro(threshold=0.25)\n",
        "                 ])\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPkZm-9Tvqy2"
      },
      "source": [
        "# Entrenamiento y evaluaci贸n de modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdbvrvRfw0JN"
      },
      "source": [
        "Calculo de cantidad de pasos por epocas en datasets base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aaV2BBViZWpL",
        "outputId": "13afc4ce-4a64-4e77-89c8-e81bca40a6ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124\n",
            "31\n",
            "495\n",
            "123\n",
            "495\n",
            "123\n"
          ]
        }
      ],
      "source": [
        "# Haciendo cuentas....\n",
        "# batch_curated_resampled_train\n",
        "steps_per_epoch = int(size_train_curated*0.8) // 32\n",
        "print(steps_per_epoch)\n",
        "validation_steps = int(size_train_curated*0.2) // 32\n",
        "print(validation_steps)\n",
        "# batch_noisy_train\n",
        "steps_per_epoch_noisy = int(size_train_noisy*0.8) // 32\n",
        "print(steps_per_epoch_noisy)\n",
        "validation_steps_noisy = int(size_train_noisy*0.2) // 32\n",
        "print(validation_steps_noisy)\n",
        "\n",
        "steps_per_epoch_mixed = 619\n",
        "print(steps_per_epoch_noisy)\n",
        "validation_steps_mixed = 154\n",
        "print(validation_steps_noisy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SMyXwAgx6oz"
      },
      "outputs": [],
      "source": [
        "num_labels = len(all_labels)\n",
        "# 16khz = (780, 13, 1)\n",
        "# 44.1khz = (2152, 13, 1)\n",
        "input_shape = (2152, 13, 1)\n",
        "\n",
        "model = build_efficientnetv2_b2_scratch(input_shape,dropout_rate=0.2, lr=0.001)\n",
        "\n",
        "EPOCHS = 25\n",
        "history = model.fit(\n",
        "      augmented_ds,\n",
        "      validation_data=mixed_val_ds,\n",
        "      steps_per_epoch=steps_per_epoch_mixed*3,  # Usar el valor calculado\n",
        "      validation_steps=validation_steps_mixed,  # Usar el valor calculado\n",
        "      epochs=EPOCHS,\n",
        "      callbacks=[\n",
        "          tf.keras.callbacks.EarlyStopping(verbose=1, patience=10, restore_best_weights=True),\n",
        "          tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, verbose=1),\n",
        "      ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3vKSuVcx-Lk"
      },
      "source": [
        "**Evaluaci贸n con lwlrap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "47A7DRufoE2p",
        "outputId": "de0b2bcb-4f00-40dd-cde6-bf7377a97351"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : EfficientnetV2_b2 base d_out=0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/facundo2588/proyecto-2/0211bf87a6ba423c85905f8f827f8b9d\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name             : EfficientnetV2_b2 base d_out=0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url     : https://colab.research.google.com/notebook#fileId=1w-KT824iDPD7UAI_FyU7Z-aHhxcmXAzA\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainable_params : 8882094\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_amsgrad                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_beta_1                      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_beta_2                      : 0.999\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_clipnorm                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_clipvalue                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_ema_momentum                : 0.99\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_ema_overwrite_frequency     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_epsilon                     : 1e-07\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_global_clipnorm             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_gradient_accumulation_steps : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_learning_rate               : 0.0010000000474974513\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_loss_scale_factor           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_name                        : adam\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_use_ema                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Adam_weight_decay                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Optimizer                        : adam\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_amsgrad                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_beta_1                      : 0.9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_beta_2                      : 0.999\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_clipnorm                    : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_clipvalue                   : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_ema_momentum                : 0.99\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_ema_overwrite_frequency     : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_epsilon                     : 1e-07\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_global_clipnorm             : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_gradient_accumulation_steps : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_learning_rate               : 0.0010000000474974513\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_loss_scale_factor           : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_use_ema                     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     adam_weight_decay                : None\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     drop_out                         : 0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs                           : 25\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                            : 1857\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/facundo2588/proyecto-2/500dcb0bf0044dc78c82e8d1bac6d176\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m tensorflow datasets are not currently supported for gradient and activation auto-logging\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 205ms/step - auc: 0.6360 - f1_macro: 0.0172 - loss: 0.0862 - val_auc: 0.7883 - val_f1_macro: 0.0336 - val_loss: 0.0744 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 33ms/step - auc: 0.5148 - f1_macro: 0.0292 - loss: 0.0577 - val_auc: 0.8042 - val_f1_macro: 0.0401 - val_loss: 0.0712 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 198ms/step - auc: 0.8097 - f1_macro: 0.0629 - loss: 0.0657 - val_auc: 0.6691 - val_f1_macro: 0.0367 - val_loss: 0.1049 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - auc: 0.5215 - f1_macro: 0.0975 - loss: 0.0533 - val_auc: 0.6833 - val_f1_macro: 0.0409 - val_loss: 0.1005 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 198ms/step - auc: 0.8448 - f1_macro: 0.1290 - loss: 0.0616 - val_auc: 0.6538 - val_f1_macro: 0.0532 - val_loss: 0.1021 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - auc: 0.5193 - f1_macro: 0.1246 - loss: 0.0502 - val_auc: 0.6845 - val_f1_macro: 0.0646 - val_loss: 0.0942 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 199ms/step - auc: 0.8701 - f1_macro: 0.1951 - loss: 0.0578 - val_auc: 0.6693 - val_f1_macro: 0.0661 - val_loss: 0.1020 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m   2/1857\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:20\u001b[0m 173ms/step - auc: 0.4588 - f1_macro: 0.1913 - loss: 0.0461\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - auc: 0.5329 - f1_macro: 0.2116 - loss: 0.0452 - val_auc: 0.6855 - val_f1_macro: 0.0715 - val_loss: 0.0979 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 200ms/step - auc: 0.9052 - f1_macro: 0.3084 - loss: 0.0510 - val_auc: 0.6539 - val_f1_macro: 0.0698 - val_loss: 0.1101 - learning_rate: 5.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - auc: 0.5472 - f1_macro: 0.2670 - loss: 0.0346 - val_auc: 0.7146 - val_f1_macro: 0.1076 - val_loss: 0.0929 - learning_rate: 5.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - auc: 0.9293 - f1_macro: 0.4113 - loss: 0.0446\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 199ms/step - auc: 0.9293 - f1_macro: 0.4113 - loss: 0.0446 - val_auc: 0.8296 - val_f1_macro: 0.2772 - val_loss: 0.0677 - learning_rate: 5.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - auc: 0.5519 - f1_macro: 0.3645 - loss: 0.0264 - val_auc: 0.8261 - val_f1_macro: 0.2714 - val_loss: 0.0685 - learning_rate: 2.5000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 199ms/step - auc: 0.9530 - f1_macro: 0.5318 - loss: 0.0363 - val_auc: 0.7386 - val_f1_macro: 0.2015 - val_loss: 0.0933 - learning_rate: 2.5000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m   2/1857\u001b[0m \u001b[37m\u001b[0m \u001b[1m5:19\u001b[0m 172ms/step - auc: 0.4784 - f1_macro: 0.4013 - loss: 0.0211\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - auc: 0.5575 - f1_macro: 0.4570 - loss: 0.0204 - val_auc: 0.7590 - val_f1_macro: 0.2220 - val_loss: 0.0883 - learning_rate: 2.5000e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 199ms/step - auc: 0.9657 - f1_macro: 0.6180 - loss: 0.0300 - val_auc: 0.7767 - val_f1_macro: 0.2667 - val_loss: 0.0846 - learning_rate: 1.2500e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m1857/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - auc: 0.5577 - f1_macro: 0.4633 - loss: 0.0163 - val_auc: 0.7644 - val_f1_macro: 0.2499 - val_loss: 0.0884 - learning_rate: 1.2500e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m1161/1857\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2:15\u001b[0m 195ms/step - auc: 0.9677 - f1_macro: 0.6381 - loss: 0.0286"
          ]
        }
      ],
      "source": [
        "# Hacer predicciones\n",
        "print(\"Realizando predicciones en conjunto de entrenamiento...\")\n",
        "pred_train = model_curated_resampled.predict(batch_curated_resampled_train_ds)\n",
        "\n",
        "print(\"Realizando predicciones en conjunto de validaci贸n...\")\n",
        "pred_val = model_curated_resampled.predict(batch_curated_resampled_val_ds)\n",
        "\n",
        "#print(\"Realizando predicciones en conjunto de validaci贸n...\")\n",
        "#pred_dev = model_curated_resampled.predict(batch_curated_resampled_dev_ds)\n",
        "\n",
        "# Extraer labels reales\n",
        "print(\"Extrayendo labels de entrenamiento...\")\n",
        "labels_train = extract_labels_from_dataset(batch_curated_resampled_train_ds)\n",
        "\n",
        "print(\"Extrayendo labels de validaci贸n...\")\n",
        "labels_val = extract_labels_from_dataset(batch_curated_resampled_val_ds)\n",
        "\n",
        "#print(\"Extrayendo labels de validaci贸n...\")\n",
        "#labels_dev = extract_labels_from_dataset(batch_curated_resampled_dev_ds)\n",
        "\n",
        "# Verificar dimensiones\n",
        "print(f\"Predicciones train: {pred_train.shape}\")\n",
        "print(f\"Labels train: {labels_train.shape}\")\n",
        "print(f\"Predicciones val: {pred_val.shape}\")\n",
        "print(f\"Labels val: {labels_val.shape}\")\n",
        "#print(f\"Predicciones val: {pred_dev.shape}\")\n",
        "#print(f\"Labels val: {labels_dev.shape}\")\n",
        "\n",
        "# Calcular LWLRAP usando las funciones que ya tienes\n",
        "print(\"\\n=== LWLRAP CONJUNTO DE ENTRENAMIENTO ===\")\n",
        "per_class_lwlrap_train, weight_per_class_train = calculate_per_class_lwlrap(labels_train, pred_train)\n",
        "train_lwlrap = np.sum(per_class_lwlrap_train * weight_per_class_train)\n",
        "print(f\"LWLRAP (m茅todo per-class): {train_lwlrap:.4f}\")\n",
        "\n",
        "train_lwlrap_sklearn = calculate_overall_lwlrap_sklearn(labels_train, pred_train)\n",
        "print(f\"LWLRAP (sklearn): {train_lwlrap_sklearn:.4f}\")\n",
        "\n",
        "print(\"\\n=== LWLRAP CONJUNTO DE VALIDACIN ===\")\n",
        "per_class_lwlrap_val, weight_per_class_val = calculate_per_class_lwlrap(labels_val, pred_val)\n",
        "val_lwlrap = np.sum(per_class_lwlrap_val * weight_per_class_val)\n",
        "print(f\"LWLRAP (m茅todo per-class): {val_lwlrap:.4f}\")\n",
        "\n",
        "val_lwlrap_sklearn = calculate_overall_lwlrap_sklearn(labels_val, pred_val)\n",
        "print(f\"LWLRAP (sklearn): {val_lwlrap_sklearn:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZdaMc1qyPP9"
      },
      "source": [
        "# Funci贸n para guardado de csv final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1R_VmJ39WXA"
      },
      "outputs": [],
      "source": [
        "# === FUNCIN PARA CREAR SUBMISSION ===\n",
        "def save_submission(test_df, predictions, output_path):\n",
        "    # Verificar dimensiones\n",
        "    print(f\"Test DF shape: {test_df.shape}\")\n",
        "    print(f\"Predictions shape: {predictions.shape}\")\n",
        "\n",
        "    # Crear copia del test_df para modificar\n",
        "    submission_df = test_df.copy()\n",
        "\n",
        "    # Las columnas de clases son todas excepto 'fname'\n",
        "    class_columns = [col for col in submission_df.columns if col != 'fname']\n",
        "\n",
        "    # Verificar que el n煤mero de clases coincida\n",
        "    if len(class_columns) != predictions.shape[1]:\n",
        "        raise ValueError(f\"Mismatch: {len(class_columns)} classes in test_df vs {predictions.shape[1]} in predictions\")\n",
        "\n",
        "    # Llenar las columnas de clases con las predicciones\n",
        "    for i, class_col in enumerate(class_columns):\n",
        "        submission_df[class_col] = predictions[:, i]\n",
        "\n",
        "    # Guardar archivo\n",
        "    submission_df.to_csv(output_path, index=False)\n",
        "    print(f\"Archivo guardado en: {output_path}\")\n",
        "\n",
        "    # Mostrar estad铆sticas\n",
        "    print(f\"Archivos procesados: {len(submission_df)}\")\n",
        "    print(f\"Predicciones promedio: {predictions.mean():.4f}\")\n",
        "    print(f\"Predicciones m谩ximas: {predictions.max():.4f}\")\n",
        "    print(f\"Predicciones m铆nimas: {predictions.min():.4f}\")\n",
        "\n",
        "    # Verificar algunos ejemplos\n",
        "    print(\"\\n=== PRIMEROS 3 EJEMPLOS ===\")\n",
        "    for i in range(min(3, len(submission_df))):\n",
        "        fname = submission_df.iloc[i]['fname']\n",
        "        sample_preds = predictions[i]\n",
        "        top_classes = sample_preds.argsort()[-5:][::-1]  # Top 5 clases\n",
        "\n",
        "        print(f\"Archivo: {fname}\")\n",
        "        print(f\"Top 5 predicciones: {sample_preds[top_classes]}\")\n",
        "        print(f\"Clases correspondientes: {[class_columns[idx] for idx in top_classes]}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    return submission_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbCnSCuaxWxi"
      },
      "source": [
        "# Predicciones test y creaci贸n de csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VjtkYT5yUw6"
      },
      "outputs": [],
      "source": [
        "# === CREAR SUBMISSION Y ENVIAR A KAGGLE ===\n",
        "print(\"=== CREANDO SUBMISSION FINAL ===\")\n",
        "\n",
        "prediction = model.predict(spect_test_ds.batch(32))\n",
        "\n",
        "# Usar las predicciones que ya tienes\n",
        "output_path = str(base_dir / 'submission_final.csv')\n",
        "submission_df = save_submission(test_df, prediction, output_path)\n",
        "\n",
        "print(\"\\n=== VERIFICACIN FINAL ===\")\n",
        "print(f\"Forma del archivo final: {submission_df.shape}\")\n",
        "print(f\"Columnas: {list(submission_df.columns)[:5]}...\")  # Mostrar primeras 5\n",
        "print(f\"Archivo guardado en: {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
